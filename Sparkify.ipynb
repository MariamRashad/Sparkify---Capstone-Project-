{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for a Spark session to start...\n",
      "Spark Initialization Done! ApplicationId = app-20200427050600-0000\n",
      "KERNEL_ID = cfc09f94-e2f1-42d5-b5ad-4a53f3b61d3c\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import ibmos2spark\n",
    "# @hidden_cell\n",
    "credentials = {\n",
    "    'endpoint': 'https://s3.eu-geo.objectstorage.service.networklayer.com',\n",
    "    'service_id': 'iam-ServiceId-9e51b6ad-1e37-4393-bbf0-54836c7c6bbc',\n",
    "    'iam_service_endpoint': 'https://iam.eu-gb.bluemix.net/oidc/token',\n",
    "    'api_key': 'UA8jNeMWxBUgJy32OfWxtJsa1bk7yOSOrpgYAYuL4xMu'\n",
    "}\n",
    "\n",
    "configuration_name = 'os_56fd1e2bb7b94877a7f99dabe7a4ba45_configs'\n",
    "cos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "# Since JSON data can be semi-structured and contain additional metadata, it is possible that you might face issues with the DataFrame layout.\n",
    "# Please read the documentation of 'SparkSession.read()' to learn more about the possibilities to adjust the data loading.\n",
    "# PySpark documentation: http://spark.apache.org/docs/2.0.2/api/python/pyspark.sql.html#pyspark.sql.DataFrameReader.json\n",
    "\n",
    "df = spark.read.json(cos.url('medium-sparkify-event-data.json', 'sparkify-donotdelete-pr-qz53avfoxtdc2u'))\n",
    "df.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, MinMaxScaler, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Sparkify Project\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"mini_sparkify_event_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_log.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_log.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(user_log.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_log.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in user_log.columns]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_log.groupby('page').count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = user_log.dropna(how = \"any\", subset = [\"userId\", \"sessionId\"])\n",
    "\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df[\"userId\"] != \"\")\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"page\").dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_users = df.filter(df.page==\"Cancellation Confirmation\").select(\"userId\").dropDuplicates()\n",
    "churn_users_list = [(row['userId']) for row in churn_users.collect()]\n",
    "withchurn = df.withColumn(\"churn\", df.userId.isin(churn_users_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withchurn.dropDuplicates([\"userId\", \"gender\"]).groupby([\"churn\", \"gender\"]).count().sort(\"churn\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theRatio = withchurn.dropDuplicates([\"userId\", \"gender\"]).groupby([\"churn\", \"gender\"]).count().sort(\"churn\").toPandas()\n",
    "sns.barplot(x='churn', y='count', hue='gender', data=theRatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghour = udf(lambda x: datetime.datetime.fromtimestamp(x / 1000.0).hour)\n",
    "withchurn = withchurn.withColumn(\"hour\", ghour(withchurn.ts))\n",
    "\n",
    "gweekday = udf(lambda x: datetime.datetime.fromtimestamp(x / 1000.0).strftime(\"%w\"))\n",
    "withchurn = withchurn.withColumn(\"weekday\", gweekday(withchurn.ts))\n",
    "\n",
    "gday = udf(lambda x: datetime.datetime.fromtimestamp(x / 1000.0).day)\n",
    "withchurn = withchurn.withColumn(\"day\", gday(withchurn.ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotbychurn(time): \n",
    "    dfpd = withchurn.filter(withchurn.page == \"NextSong\").groupby(\"churn\", time).count().orderBy(withchurn[time].cast(\"float\")).toPandas()\n",
    "    dfpd[time] = pd.to_numeric(dfpd[time])\n",
    "    dfpd[ dfpd.churn==0].plot.bar(x=time, y='count', color='grey', label='Non churned')\n",
    "    dfpd[ dfpd.churn==1].plot.bar(x=time, y='count', color='pink', label='Churned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotbychurn(\"hour\")\n",
    "\n",
    "plotbychurn(\"weekday\")\n",
    "\n",
    "plotbychurn(\"day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withchurn.dropDuplicates([\"userId\", \"gender\"]).groupby([\"churn\", \"gender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[{}] Start'.format(datetime.datetime.now()))\n",
    "print('[{}] Done'.format(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.drop('artist', 'auth', 'firstName', 'gender',\n",
    "                 'itemInSession', 'lastName', 'length', 'location', 'method', 'registration', 'sessionId', 'song', 'avg_hr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_gender = StringIndexer(inputCol=\"gender\", outputCol='index_gender')\n",
    "index_page = StringIndexer(inputCol=\"page\", outputCol='index_page')\n",
    "genderVec = OneHotEncoder(inputCol='index_gender', outputCol='genderVec')\n",
    "pageVec = OneHotEncoder(inputCol='index_page', outputCol='pageVec')\n",
    "assembler = VectorAssembler(inputCols=[\"genderVec\", \"pageVec\", \"status\"], outputCol=\"features\")\n",
    "index = StringIndexer(inputCol=\"churn\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df_new.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logestic_reg=  LogisticRegression()\n",
    "\n",
    "pipeline = Pipeline(stages=[Logestic_reg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(Logestic_reg.elasticNetParam,[0.0, 0.5, 1.0]) \\\n",
    "    .addGrid(Logestic_reg.regParam,[0.0, 0.01, 0.1]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 with Spark",
   "language": "python3",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
